{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoLpZSootzDk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Charger les segments\n",
        "data = np.load(\"segments_npz/segments_batch_1.npz\")\n",
        "X = data['X']  # shape: (nb_segments, 256)\n",
        "y = data['y']  # shape: (nb_segments,)\n",
        "\n",
        "# Normalisation (important pour LSTM)\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Découper en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir en tenseurs pour LSTM (batch, sequence, features)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)  # (batch, 256, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class EEG_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EEG_LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(64, 2)  # 2 classes : crise ou non\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)       # out: (batch, seq_len, hidden)\n",
        "        out = out[:, -1, :]         # on prend le dernier état caché\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "z09avohrudJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Préparer le DataLoader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Initialiser modèle, perte, optimiseur\n",
        "model = EEG_LSTM()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Entraînement\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Époque {epoch+1} - Perte: {total_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "X2mw9cG5ujGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "        total += batch_y.size(0)\n",
        "\n",
        "print(f\"Précision sur test : {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "MECJEWlRusZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}